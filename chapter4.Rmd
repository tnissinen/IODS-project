# Chapter 4: Clustering and classification

### Loading and checking the structure of the data

```{r readdata_mass,echo=TRUE,results='hide',message=FALSE,warning=FALSE}

# access the MASS package
library(MASS)
library(dplyr)
library(tidyr)
library(corrplot)
library(ggplot2)

```

```{r}
# load the data
data("Boston")

# explore the dataset
str(Boston)
summary(Boston)

```

The dataset contains housing values in suburbs of Boston. It has 506 observations with 14 variables. It also contains the crime rate per capita by town.


### Graphical overview of the data

The plot matrix of the variables:

```{r fig_mass2, fig.path="figures/", fig.dim=c(10,10), results='hide', message=FALSE, warning=FALSE}

# plot matrix of the variables
pairs(Boston)

```


Three clear correlations pop up from the matrix. Let's take a closer look...

Crime and age
```{r}

qplot(age, crim, data = Boston) + geom_smooth(method = "lm")

```

Crime and weighted mean of distances to five Boston employment centres.
```{r}

qplot(dis, crim, data = Boston) + geom_smooth(method = "lm")

```

Crime and median value of owner-occupied homes. 
```{r}

qplot(medv, crim, data = Boston) + geom_smooth(method = "lm")

```

The correlations between variables can be also examined from the correlations matrix:

```{r}

# calculate the correlation matrix and round it
cor_matrix<-cor(Boston) 

# print the correlation matrix
cor_matrix %>% round(2)

# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)


```



### Standardize the dataset

Scaling the data

```{r}

# center and standardize variables
boston_scaled <- scale(Boston)

boston_scaled <- as.data.frame(boston_scaled)

# summaries of the scaled variables
summary(boston_scaled)

```


Create cathegorical values:

```{r}

# create a quantile vector of crim and print it
bins <- quantile(boston_scaled$crim)
bins

# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))

table(crime)

# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)


```


Splitting to train and test sets

```{r, results='asis'}

# number of rows in the Boston dataset 
n <- nrow(Boston)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create train set
train <- boston_scaled[ind,]

# create test set 
test <- boston_scaled[-ind,]


```


### Fitting the LDA model

```{r}

# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)

# print the lda.fit object
lda.fit

# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results
plot(lda.fit, col = classes, pch = classes, dimen = 2)
lda.arrows(lda.fit, myscale = 1)

```

We can see distinct groups of crime rate categories with some overlap

### Predicting the classes and cross tabulation

```{r}

# save the correct classes from test data
correct_classes <- test$crime

# remove the crime variable from test data
test <- dplyr::select(test, -crime)

# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)

```


Overall accuracy of predictions:

```{r}
mean(lda.pred$class==correct_classes)
```

We can see that our model correctly classified over 70% of observations, which is fairly good result. 
